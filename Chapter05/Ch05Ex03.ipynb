{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "metadata": {
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      },
      "source": [
        "%%pyspark\r\n",
        "df = spark.read.load('abfss://brainjammer@csharpguitar.dfs.core.windows.net/EMEA/brainjammer/in/2022/04/28/16/*.parquet', format='parquet')\r\n",
        "#print(\"Total brainwave readings: \" + str(df.distinct().count()))\r\n",
        "#display(df.limit(10))\r\n",
        "df.registerTempTable(\"TmpREADING\")\r\n",
        "# LOAD MODE\r\n",
        "dfMODE = spark.read.load('abfss://brainjammer@csharpguitar.dfs.core.windows.net/Tables/MODE.csv', format='csv', header=True)\r\n",
        "dfMODE.createOrReplaceTempView(\"MODE\")\r\n",
        "#print(\"MODEs: \" + str(dfMODE.distinct().count()))\r\n",
        "# LOAD ELECTRODE\r\n",
        "dfELECTRODE = spark.read.load('abfss://brainjammer@csharpguitar.dfs.core.windows.net/Tables/ELECTRODE.csv', format='csv', header=True)\r\n",
        "dfELECTRODE.createOrReplaceTempView(\"ELECTRODE\")\r\n",
        "#print(\"ELECTRODEs: \" + str(dfELECTRODE.distinct().count()))\r\n",
        "# LOAD FREQUENCY\r\n",
        "dfFREQUENCY = spark.read.load('abfss://brainjammer@csharpguitar.dfs.core.windows.net/Tables/FREQUENCY.csv', format='csv', header=True)\r\n",
        "dfFREQUENCY.createOrReplaceTempView(\"FREQUENCY\")\r\n",
        "#print(\"FREQUENCYs: \" + str(dfFREQUENCY.distinct().count()))\r\n",
        "# LOAD SCENARIO\r\n",
        "dfSCENARIO = spark.read.load('abfss://brainjammer@csharpguitar.dfs.core.windows.net/Tables/SCENARIO.csv', format='csv', header=True)\r\n",
        "dfSCENARIO.createOrReplaceTempView(\"SCENARIO\")\r\n",
        "#print(\"SCENARIOs: \" + str(dfSCENARIO.distinct().count()))\r\n",
        "# LOAD SESSION\r\n",
        "dfSESSION = spark.read.load('abfss://brainjammer@csharpguitar.dfs.core.windows.net/Tables/SESSIONALL.csv', format='csv', header=True)\r\n",
        "dfSESSION.createOrReplaceTempView(\"SESSION\")\r\n",
        "#print(\"SESSIONs: \" + str(dfSESSION.distinct().count()))\r\n",
        "dfREADING = sqlContext.sql(\"\"\"\r\n",
        "    SELECT  se.SESSION_DATETIME, r.READING_DATETIME, \r\n",
        "            s.SCENARIO, e.ELECTRODE, f.FREQUENCY, r.VALUE\r\n",
        "    FROM    SESSION se, TmpREADING r, SCENARIO s, \r\n",
        "            ELECTRODE e, FREQUENCY f\r\n",
        "    WHERE   r.SESSION_ID = se.SESSION_ID AND se.SCENARIO_ID = s.SCENARIO_ID \r\n",
        "            AND r.ELECTRODE_ID = e.ELECTRODE_ID AND r.FREQUENCY_ID = f.FREQUENCY_ID\r\n",
        "\"\"\")\r\n",
        "#print(\"READINGs: \" + str(dfREADING.distinct().count()))\r\n",
        "#display(dfREADING.limit(10))\r\n",
        "dfREADING.write.parquet('abfss://brainjammer@csharpguitar.dfs.core.windows.net/EMEA/brainjammer/out/2022/04/28/17/BrainjammerBrainwavesSpark.parquet')\r\n",
        "#dfFactREADING = spark.read.load('abfss://brainjammer@csharpguitar.dfs.core.windows.net/EMEA/brainjammer/out/2022/04/28/17/BrainjammerBrainwavesSpark.parquet', format='parquet')\r\n",
        "#print(\"Total brainwave readings: \" + str(dfFactREADING.distinct().count()))\r\n",
        "#display(dfFactREADING.limit(100))"
      ]
    }
  ]
}